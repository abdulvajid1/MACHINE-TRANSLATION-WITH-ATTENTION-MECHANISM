{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "3G1HJjntrcjc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import RMSprop\n",
        "\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read data\n",
        "with open('mal-eng\\mal.txt','r') as file:\n",
        "    data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello.\tനമസ്കാരം.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1858850 (LanguageExpert) & #651913 (jjrodz)\n",
            "Really?\tശരിക്കും?\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #7896041 (lonewolfie)\n",
            "Help me.\tഎന്നെ സഹായിക്കൂ.\tCC-BY 2.0 (France) Attribution: tatoeba.org #266065 (Zifre) & #780454 (jjrodz)\n",
            "Welcome.\tസ്വാഗതം.\tCC-BY 2.0 (France) Attribution: tatoeba.org #138919 (CM) & #7896035 (lonewolfie)\n",
            "I forgot.\tഞാന്‍ മറന്നു.\tCC-BY 2.0 (France) Attribution: tatoeba.org #436603 (lukasz\n"
          ]
        }
      ],
      "source": [
        "print(data[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp_tar_data = [text.split('\\t')[:2] for text in data.split('\\n')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Hello.', 'നമസ്കാരം.'], ['Really?', 'ശരിക്കും?'], ['Help me.', 'എന്നെ സഹായിക്കൂ.'], ['Welcome.', 'സ്വാഗതം.'], ['I forgot.', 'ഞാന്\\u200d മറന്നു.']]\n"
          ]
        }
      ],
      "source": [
        "print(inp_tar_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp_data = []\n",
        "tar_data = []\n",
        "for item in inp_tar_data:\n",
        "    if len(item)<2:\n",
        "        continue\n",
        "    inp_data.append(item[0])\n",
        "    tar_data.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of data in inp:  614\n",
            "number of data in tar:  614\n"
          ]
        }
      ],
      "source": [
        "print('number of data in inp: ',len(inp_data))\n",
        "print('number of data in tar: ',len(tar_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Hello.', 'നമസ്കാരം.'), ('Really?', 'ശരിക്കും?'), ('Help me.', 'എന്നെ സഹായിക്കൂ.'), ('Welcome.', 'സ്വാഗതം.')]\n"
          ]
        }
      ],
      "source": [
        "print(list(zip(inp_data,tar_data[:4])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove puctuations\n",
        "def remove_puctuations(word):\n",
        "    word = re.sub('[{}]'.format(string.punctuation),repl='',string=word)\n",
        "    return word.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp_data = list(map(remove_puctuations,inp_data))\n",
        "tar_data = list(map(remove_puctuations,tar_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['നമസ്കാരം', 'ശരിക്കും', 'എന്നെ സഹായിക്കൂ', 'സ്വാഗതം']\n"
          ]
        }
      ],
      "source": [
        "print(tar_data[:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LangPorcess:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.__word2int = {}\n",
        "        self.__int2word = {}\n",
        "        self.__vocabsize = 2\n",
        "        self.__word2int['<pad>'] = 0\n",
        "        self.__int2word[0] = '<pad>'\n",
        "        self.__int2word[1] = '<eos>'\n",
        "        self.__word2int['<eos>'] = 1\n",
        "        self.__word_freq = {}\n",
        "        self.__integer_encoded =[]\n",
        "\n",
        "    def fit(self,X):\n",
        "        X_split_words = [text.split(' ') for text in X]\n",
        "        self.read_sentences(X_split_words)\n",
        "        self.__integer_encoding(X_split_words)\n",
        "        \n",
        "        \n",
        "    def read_sentences(self,X):\n",
        "        # Loop thourgh each sentence and read words\n",
        "        for sentence in X:\n",
        "            for word in sentence:\n",
        "                if word not in self.__word2int.keys():\n",
        "                    self.__word_freq[word] = 1\n",
        "                    self.read_words(word)\n",
        "                else:\n",
        "                    self.__word_freq[word] += 1\n",
        "\n",
        "\n",
        "    \n",
        "    def read_words(self,word):\n",
        "            self.__word2int[word] = self.__vocabsize\n",
        "            self.__int2word[self.__vocabsize] = word\n",
        "            self.__vocabsize+=1\n",
        "\n",
        "    def get_word_frequency(self):\n",
        "        return dict(sorted(self.__word_freq.items(),\n",
        "                           key=lambda x:x[1],\n",
        "                           reverse=True))\n",
        "    \n",
        "    def get_word2index(self):\n",
        "        return self.__int2word\n",
        "    \n",
        "    def get_index2word(self):\n",
        "        return self.__word2int\n",
        "    \n",
        "    def __integer_encoding(self,X):  \n",
        "        for word in X:\n",
        "            torch_tensor = torch.tensor(list(map(lambda word : self.__word2int[word],word)))\n",
        "            self.__integer_encoded.append(torch_tensor)\n",
        "\n",
        "    def get_integer_encoding(self,padding=True,max_len=None):\n",
        "        if padding:\n",
        "            return self.__pad_sequence(self.__integer_encoded,max_len)\n",
        "        else:\n",
        "            return self.__integer_encoded\n",
        "        \n",
        "    def __pad_sequence(self,X,max_len):\n",
        "            maxlen_padded = pad_sequence(self.__integer_encoded,padding_value=0,batch_first=True)\n",
        "            if max_len:\n",
        "                return maxlen_padded[:,:max_len]\n",
        "            else:\n",
        "                return maxlen_padded\n",
        "    \n",
        "    def get_vocabsize(self):\n",
        "        return self.__vocabsize\n",
        "       \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp_lang = LangPorcess()\n",
        "inp_lang.fit(inp_data)\n",
        "\n",
        "tar_lang = LangPorcess()\n",
        "tar_lang.fit(tar_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "inp_integers = inp_lang.get_integer_encoding(max_len=11)\n",
        "tar_integers = tar_lang.get_integer_encoding(max_len=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TorchDataset(Dataset):\n",
        "    def __init__(self,enc_sentance,dec_sentance):\n",
        "        super().__init__()\n",
        "        self.enc_sentance = enc_sentance\n",
        "        self.dec_sentance = dec_sentance\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.enc_sentance)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.enc_sentance[index], self.dec_sentance[index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = TorchDataset(enc_sentance=inp_integers,dec_sentance=tar_integers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(data,\n",
        "                        batch_size=32,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[870, 734, 206, 871, 872, 149, 293,   0,   0,   0,   0],\n",
            "        [ 51, 855,  52, 244, 788,  81,  46,   0,   0,   0,   0],\n",
            "        [505, 115, 248, 116, 585, 586,   0,   0,   0,   0,   0],\n",
            "        [ 49, 639,  33, 640, 571, 572,   0,   0,   0,   0,   0],\n",
            "        [ 13,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 24,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 49, 120,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  7, 186, 142, 494, 174,  49, 598,   0,   0,   0,   0],\n",
            "        [ 60, 366,  79, 367, 274,   0,   0,   0,   0,   0,   0],\n",
            "        [  7, 190, 100, 401, 506,  51,   0,   0,   0,   0,   0],\n",
            "        [ 65, 103,  52,  79, 150, 444,   0,   0,   0,   0,   0],\n",
            "        [ 29, 210,  65, 212,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 24,  91,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [493,   7, 355,  29,  52, 494,   0,   0,   0,   0,   0],\n",
            "        [ 88, 152,  19, 180, 915,  51, 610, 916,   0,   0,   0],\n",
            "        [ 24,  73,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [248,   7,  47,  52,  48,   0,   0,   0,   0,   0,   0],\n",
            "        [745,  59,  19, 746,  77, 248,  81,  17,   0,   0,   0],\n",
            "        [ 29, 245, 145,  41, 163, 571, 463,   0,   0,   0,   0],\n",
            "        [  7,  16,  63,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  7, 262,  19, 294,  17,   0,   0,   0,   0,   0,   0],\n",
            "        [  7, 140, 138, 256, 257,   0,   0,   0,   0,   0,   0],\n",
            "        [ 69,  70,  71,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  7, 111,  79, 112,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 49, 183, 787, 849, 589,  79, 850, 393,   0,   0,   0],\n",
            "        [ 70,  71, 168, 235, 105, 651,   0,   0,   0,   0,   0],\n",
            "        [  7, 190, 574,  19, 575, 576,   0,   0,   0,   0,   0],\n",
            "        [ 97,  19,  98,  81, 416, 537,   0,   0,   0,   0,   0],\n",
            "        [100,  19, 294, 401, 256,  50, 686,   0,   0,   0,   0],\n",
            "        [  7, 186,  46,  70, 841, 323,  51, 393,   0,   0,   0],\n",
            "        [ 29, 267, 503, 244, 344,   0,   0,   0,   0,   0,   0],\n",
            "        [ 24,  72,   0,   0,   0,   0,   0,   0,   0,   0,   0]]) tensor([[1243, 1244, 1245, 1246, 1236,    0,    0],\n",
            "        [ 252, 1217,  669,  255, 1218,    0,    0],\n",
            "        [ 761,  762,  763,  377,  764,    0,    0],\n",
            "        [ 121,  735,  736,  706,  739,    0,    0],\n",
            "        [  13,   14,    0,    0,    0,    0,    0],\n",
            "        [  25,   39,   27,    0,    0,    0,    0],\n",
            "        [ 121,  122,  123,    0,    0,    0,    0],\n",
            "        [  53,  785,    9,  786,  787,    0,    0],\n",
            "        [  97,  111,  150,  427,  428,    0,    0],\n",
            "        [   7,  624,  380,  412,  625,  500,    0],\n",
            "        [  66,  105,  150,  533,  534,    0,    0],\n",
            "        [  97,   66,  221,  222,    0,    0,    0],\n",
            "        [  25,   91,   27,    0,    0,    0,    0],\n",
            "        [ 607,  608,   97,  609,    0,    0,    0],\n",
            "        [1301,  217,  252, 1302,   86, 1303,    0],\n",
            "        [  25,   74,   27,    0,    0,    0,    0],\n",
            "        [ 263,  264,  265,    0,    0,    0,    0],\n",
            "        [ 308, 1021,   21, 1022, 1023,   27,    0],\n",
            "        [  36,  819,  166,  820,    0,    0,    0],\n",
            "        [   9,   64,   65,    0,    0,    0,    0],\n",
            "        [ 323,   17,  324,  325,    7,  326,    0],\n",
            "        [   7,  271,  272,  273,  142,    0,    0],\n",
            "        [  70,   71,   72,    0,    0,    0,    0],\n",
            "        [ 114,  115,   52,    0,    0,    0,    0],\n",
            "        [ 150,  461,  771, 1207,  121,   38,    0],\n",
            "        [  70,  247,  859,  346,  860,    0,    0],\n",
            "        [  11,  100,  745,  746,  747,  530,    0],\n",
            "        [ 308,  676,  769,   99,    0,    0,    0],\n",
            "        [1118, 1119, 1120,  881,    0,    0,    0],\n",
            "        [   9,  252, 1225, 1226, 1227,    0,    0],\n",
            "        [  31,  618,  259,   20,    0,    0,    0],\n",
            "        [  25,   73,   27,    0,    0,    0,    0]])\n"
          ]
        }
      ],
      "source": [
        "for i,(inp,ter) in enumerate(dataloader):\n",
        "    if i ==1:\n",
        "        break\n",
        "    print(inp,ter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "lPp3w84uZiHC"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, \n",
        "               embedding_size, \n",
        "               hidden_size, \n",
        "               vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    # encoder initialization\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                             embedding_dim=embedding_size)\n",
        "    self.encoder_lstm = nn.LSTM(input_size=embedding_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           batch_first=True)\n",
        "\n",
        "  def forward(self,input):\n",
        "    # network flow\n",
        "    embedding_input = self.embedding(input)\n",
        "    encoder_outputs, (final_hidden_state, final_cell_state) = self.encoder_lstm(embedding_input)\n",
        "    \n",
        "    return encoder_outputs.to(device), final_hidden_state.to(device), final_cell_state.to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "          nn.Linear(2*hidden_size,hidden_size),\n",
        "          nn.SELU(),\n",
        "          nn.Linear(hidden_size,1),\n",
        "          nn.Softmax(dim=1)\n",
        "        )\n",
        "    \n",
        "  def forward(self,encoder_outputs,hidden_state):\n",
        "    \"\"\" Concat encoeder_output and hidden_state, encoder_output shape = (32,timestept,hidden_size), hidden_state shape = 32,1,hidden_side\n",
        "    first we need to make it same shape to concat hidden_state should be 32,timestep hidden_size, timestpe will be repeatation of same one vector from hidden size\"\"\"\n",
        "\n",
        "    encoder_timestep_len = encoder_outputs.size(1)  # hidden_size will be (1,32,hidden_size) according to doc we need to change\n",
        "    hidden_state = hidden_state.permute(1,0,2) # shape: (32,1,5)\n",
        "    hidden_repeated = hidden_state.repeat(1,encoder_timestep_len,1) # hidden_state repetation \n",
        "\n",
        "    # concat with encoder_output and hidden output\n",
        "    encoder_hidden_concat = torch.concat((encoder_outputs,hidden_repeated),dim=-1) # shape : 32,timestep,hidden_size*2\n",
        "    weights = self.network(encoder_hidden_concat) # (32,timestepe,1)\n",
        "    weights = weights.permute(0,2,1) # for bmm (32,1,timesteps)\n",
        "    context_vectores = weights.bmm(encoder_outputs) # 32,1,hidden_size\n",
        "    context_vectores = context_vectores.permute(1,0,2) # convert back to the way lstm take hidden state\n",
        "\n",
        "    return context_vectores.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "Q-0NVAH5Zq7w"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_dim,\n",
        "               hidden_size,\n",
        "               vocab_size_tr,\n",
        "               max_len=20,\n",
        "               sos_token=1,\n",
        "               ):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.MAX_LEN = max_len\n",
        "    self.SOS_TOKEN = sos_token\n",
        "\n",
        "    # Layers Initialization\n",
        "    self.embedding_layer = nn.Embedding(vocab_size_tr, embedding_dim)\n",
        "    self.lstm_layer = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
        "    self.fnn = nn.Linear(hidden_size ,vocab_size_tr)\n",
        "    self.attention_vector = Attention(hidden_size)\n",
        "\n",
        "  def forward(self,\n",
        "              encoder_outputs,\n",
        "              hidden_state,\n",
        "              cell_state,\n",
        "              target_output=None):\n",
        "    \n",
        "    batch_size = encoder_outputs.shape[0]     # encoder gets the input from train loader which defines the batchsize\n",
        "    decoder_input = torch.empty(size=(batch_size,1),dtype=torch.long).fill_(self.SOS_TOKEN).to(device)     # Initialize first input [32 sos_tokens]\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for i in range(self.MAX_LEN):\n",
        "      output_logits ,hidden_state, cell_state = self.forward_step(encoder_outputs, decoder_input, hidden_state, cell_state)\n",
        "      decoder_outputs.append(output_logits.unsqueeze(1))      # decoder ouput = [(32,vocab_size),...(32,vocab_size)], this list will have max_len item , lastly we will concat this to make (32,max_len,vocab_size)\n",
        "\n",
        "      # teacher_forcing, occurs if we give target_output in the decoder\n",
        "      if target_output != None:\n",
        "        decoder_input = target_output[:,i].unsqueeze(1)\n",
        "      else:\n",
        "        _, decoder_input = output_logits.topk(1,dim=-1)\n",
        "\n",
        "    decoder_final_output = torch.cat(decoder_outputs,dim=1)\n",
        "    return decoder_final_output\n",
        "\n",
        "  def forward_step(self,encoder_outputs, decoder_input, hidden_state, cell_state):\n",
        "    embedded_decoder_input = self.embedding_layer(decoder_input)      # embedded shape : (32,1,embedd_size), here 1 , becuase we are giving each word or token to decoder and make it predict next word\n",
        "    lstm_output, (decoder_hidden, decoder_cell) = self.lstm_layer(embedded_decoder_input, (hidden_state, cell_state))     # lstm_output: (32,1,hidden_size)\n",
        "    output_logit = self.fnn(lstm_output.squeeze(1))   # squeeze (32,1,hidden_size) -> 32,hidden_size\n",
        "    hidden_state = self.attention_vector(encoder_outputs, decoder_hidden)     # ouput_logits: (32,vocab_size) , 32 prediction of word , we will pic top item\n",
        "\n",
        "    return output_logit ,hidden_state , decoder_cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "W6_hxStX4-K9"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqAttentionModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_size,\n",
        "               hidden_size,\n",
        "               vocab_size_en,\n",
        "               vocab_size_tr,\n",
        "               max_len=10):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(embedding_size,\n",
        "                           hidden_size,\n",
        "                           vocab_size_en).to(device)\n",
        "\n",
        "    self.decoder = Decoder(embedding_size,\n",
        "                           hidden_size,\n",
        "                           vocab_size_tr,\n",
        "                           max_len,\n",
        "                           sos_token=1).to(device)\n",
        "\n",
        "  def forward(self, input, target_output):\n",
        "    encoder_outputs = self.encoder(input)\n",
        "    decoder_output = self.decoder(*encoder_outputs, target_output)\n",
        "\n",
        "    return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total loss in 0 epoch: 139.80858278274536\n",
            "total loss in 1 epoch: 109.48159456253052\n",
            "total loss in 2 epoch: 71.30203461647034\n",
            "total loss in 3 epoch: 43.60278367996216\n",
            "total loss in 4 epoch: 33.63326382637024\n",
            "total loss in 5 epoch: 28.15714418888092\n",
            "total loss in 6 epoch: 25.47776472568512\n",
            "total loss in 7 epoch: 22.241537988185883\n",
            "total loss in 8 epoch: 21.227601885795593\n",
            "total loss in 9 epoch: 19.89553701877594\n",
            "total loss in 10 epoch: 18.277955651283264\n",
            "total loss in 11 epoch: 16.91954356431961\n",
            "total loss in 12 epoch: 16.13198083639145\n",
            "total loss in 13 epoch: 15.00713324546814\n",
            "total loss in 14 epoch: 14.394410789012909\n",
            "total loss in 15 epoch: 13.227021038532257\n",
            "total loss in 16 epoch: 12.831606924533844\n",
            "total loss in 17 epoch: 11.88662937283516\n",
            "total loss in 18 epoch: 11.044437170028687\n",
            "total loss in 19 epoch: 10.554275959730148\n",
            "total loss in 20 epoch: 10.062704175710678\n",
            "total loss in 21 epoch: 9.742398142814636\n",
            "total loss in 22 epoch: 8.86750590801239\n",
            "total loss in 23 epoch: 8.18233509361744\n",
            "total loss in 24 epoch: 7.81954425573349\n",
            "total loss in 25 epoch: 6.697011858224869\n",
            "total loss in 26 epoch: 5.994937941431999\n",
            "total loss in 27 epoch: 5.158169470727444\n",
            "total loss in 28 epoch: 4.702149361371994\n",
            "total loss in 29 epoch: 4.51703105866909\n",
            "total loss in 30 epoch: 8.661918237805367\n",
            "total loss in 31 epoch: 9.256182104349136\n",
            "total loss in 32 epoch: 5.928030610084534\n",
            "total loss in 33 epoch: 3.805216684937477\n",
            "total loss in 34 epoch: 2.3577891141176224\n",
            "total loss in 35 epoch: 1.7483172230422497\n",
            "total loss in 36 epoch: 1.3892080374062061\n",
            "total loss in 37 epoch: 1.0872372686862946\n",
            "total loss in 38 epoch: 1.0173341929912567\n",
            "total loss in 39 epoch: 0.7755495347082615\n",
            "total loss in 40 epoch: 0.6160105792805552\n",
            "total loss in 41 epoch: 0.44196867290884256\n",
            "total loss in 42 epoch: 0.38075738679617643\n",
            "total loss in 43 epoch: 0.49594773165881634\n",
            "total loss in 44 epoch: 0.4230920737609267\n",
            "total loss in 45 epoch: 0.28722689277492464\n",
            "total loss in 46 epoch: 0.2607116852886975\n",
            "total loss in 47 epoch: 0.2284006280824542\n",
            "total loss in 48 epoch: 0.2470632428303361\n",
            "total loss in 49 epoch: 0.21456882287748158\n",
            "total loss in 50 epoch: 0.3268468340393156\n",
            "total loss in 51 epoch: 1.2565866746008396\n",
            "total loss in 52 epoch: 6.881734490394592\n",
            "total loss in 53 epoch: 6.624655440449715\n",
            "total loss in 54 epoch: 3.2457120455801487\n",
            "total loss in 55 epoch: 1.5059604458510876\n",
            "total loss in 56 epoch: 0.702987409196794\n",
            "total loss in 57 epoch: 0.2893068194389343\n",
            "total loss in 58 epoch: 0.21276466269046068\n",
            "total loss in 59 epoch: 0.191864721942693\n",
            "total loss in 60 epoch: 0.17521618446335196\n",
            "total loss in 61 epoch: 0.16549716028384864\n",
            "total loss in 62 epoch: 0.15918053034693003\n",
            "total loss in 63 epoch: 0.14328147051855922\n",
            "total loss in 64 epoch: 0.14304163120687008\n",
            "total loss in 65 epoch: 0.12037438410334289\n",
            "total loss in 66 epoch: 0.12503549503162503\n",
            "total loss in 67 epoch: 0.12676002900116146\n",
            "total loss in 68 epoch: 0.1221610865322873\n",
            "total loss in 69 epoch: 0.13479845493566245\n",
            "total loss in 70 epoch: 0.11172561004059389\n",
            "total loss in 71 epoch: 0.11397869151551276\n",
            "total loss in 72 epoch: 0.10505101562011987\n",
            "total loss in 73 epoch: 0.12237203295808285\n",
            "total loss in 74 epoch: 0.13237462908728048\n",
            "total loss in 75 epoch: 0.1254001801717095\n",
            "total loss in 76 epoch: 0.13612747512524948\n",
            "total loss in 77 epoch: 0.10485742724267766\n",
            "total loss in 78 epoch: 0.13922515220474452\n",
            "total loss in 79 epoch: 0.102143747091759\n",
            "total loss in 80 epoch: 0.15562746726209298\n",
            "total loss in 81 epoch: 0.6190749106463045\n",
            "total loss in 82 epoch: 6.352070450782776\n",
            "total loss in 83 epoch: 6.372717157006264\n",
            "total loss in 84 epoch: 1.9596335031092167\n",
            "total loss in 85 epoch: 0.4422235479578376\n",
            "total loss in 86 epoch: 0.20981484465301037\n",
            "total loss in 87 epoch: 0.14620803017169237\n",
            "total loss in 88 epoch: 0.1304413186153397\n",
            "total loss in 89 epoch: 0.12482547911349684\n",
            "total loss in 90 epoch: 0.11127670016139746\n",
            "total loss in 91 epoch: 0.11053546611219645\n",
            "total loss in 92 epoch: 0.10656282119452953\n",
            "total loss in 93 epoch: 0.10462931694928557\n",
            "total loss in 94 epoch: 0.09578793775290251\n",
            "total loss in 95 epoch: 0.09407894895412028\n",
            "total loss in 96 epoch: 0.09655824629589915\n",
            "total loss in 97 epoch: 0.07894224021583796\n",
            "total loss in 98 epoch: 0.13739819335751235\n",
            "total loss in 99 epoch: 0.10367587098153308\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 128\n",
        "hidden_size = 128\n",
        "inp_vocabsize = inp_lang.get_vocabsize() + 1\n",
        "tar_vocabsize = tar_lang.get_vocabsize() + 1\n",
        "epoch = 100\n",
        "max_len = 7\n",
        "model = Seq2SeqAttentionModel(embedding_size,\n",
        "                              hidden_size,\n",
        "                              inp_vocabsize,\n",
        "                              tar_vocabsize,\n",
        "                              max_len=max_len)\n",
        "model.to(device)\n",
        "criteria = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = RMSprop(model.parameters())\n",
        "\n",
        "\n",
        "for epoch_num in range(epoch):\n",
        "    total_loss = 0\n",
        "    for input_sentance, target_sentance in dataloader:\n",
        "        input_sentance,  target_sentance = input_sentance.to(device), target_sentance.to(device)\n",
        "        output = model(input_sentance,target_sentance)\n",
        "        output.to(device)\n",
        "        target_sentance = target_sentance.view(-1)\n",
        "        output = output.view(target_sentance.shape[0],tar_vocabsize)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criteria(output,target_sentance)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'total loss in {epoch_num} epoch:',total_loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPU",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
