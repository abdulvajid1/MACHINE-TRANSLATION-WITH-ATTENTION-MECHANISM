{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3G1HJjntrcjc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read data\n",
        "with open('mal-eng\\mal.txt','r') as file:\n",
        "    data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello.\tനമസ്കാരം.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1858850 (LanguageExpert) & #651913 (jjrodz)\n",
            "Really?\tശരിക്കും?\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #7896041 (lonewolfie)\n",
            "Help me.\tഎന്നെ സഹായിക്കൂ.\tCC-BY 2.0 (France) Attribution: tatoeba.org #266065 (Zifre) & #780454 (jjrodz)\n",
            "Welcome.\tസ്വാഗതം.\tCC-BY 2.0 (France) Attribution: tatoeba.org #138919 (CM) & #7896035 (lonewolfie)\n",
            "I forgot.\tഞാന്‍ മറന്നു.\tCC-BY 2.0 (France) Attribution: tatoeba.org #436603 (lukasz\n"
          ]
        }
      ],
      "source": [
        "print(data[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "eng_ml_data = [text.split('\\t')[:2] for text in data.split('\\n')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Hello.', 'നമസ്കാരം.'], ['Really?', 'ശരിക്കും?'], ['Help me.', 'എന്നെ സഹായിക്കൂ.'], ['Welcome.', 'സ്വാഗതം.'], ['I forgot.', 'ഞാന്\\u200d മറന്നു.']]\n"
          ]
        }
      ],
      "source": [
        "print(eng_ml_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "eng_data = []\n",
        "mal_data = []\n",
        "for item in eng_ml_data:\n",
        "    if len(item)<2:\n",
        "        continue\n",
        "    eng_data.append(item[0])\n",
        "    mal_data.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of data in eng:  614\n",
            "number of data in mal:  614\n"
          ]
        }
      ],
      "source": [
        "print('number of data in eng: ',len(eng_data))\n",
        "print('number of data in mal: ',len(mal_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Hello.', 'നമസ്കാരം.'), ('Really?', 'ശരിക്കും?'), ('Help me.', 'എന്നെ സഹായിക്കൂ.'), ('Welcome.', 'സ്വാഗതം.')]\n"
          ]
        }
      ],
      "source": [
        "print(list(zip(eng_data,mal_data[:4])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove puctuations\n",
        "def remove_puctuations(word):\n",
        "    word = re.sub('[{}]'.format(string.punctuation),repl='',string=word)\n",
        "    return word.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "eng_data = list(map(remove_puctuations,eng_data))\n",
        "mal_data = list(map(remove_puctuations,mal_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['നമസ്കാരം', 'ശരിക്കും', 'എന്നെ സഹായിക്കൂ', 'സ്വാഗതം']\n"
          ]
        }
      ],
      "source": [
        "print(mal_data[:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LangPorcess:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.__word2int = {}\n",
        "        self.__int2word = {}\n",
        "        self.__num_unique_tokens = 1\n",
        "        self.__word2int['SOS'] = 0\n",
        "        self.__int2word[0] = 'SOS'\n",
        "        self.__word_freq = {}\n",
        "        self.__integer_encoded =[]\n",
        "\n",
        "    def fit(self,X):\n",
        "        X_split_words = [text.split(' ') for text in X]\n",
        "        self.read_sentences(X_split_words)\n",
        "        self.__integer_encoding(X_split_words)\n",
        "        \n",
        "        \n",
        "    def read_sentences(self,X):\n",
        "        # Loop thourgh each sentence and read words\n",
        "        for sentence in X:\n",
        "            for word in sentence:\n",
        "                if word not in self.__word2int.keys():\n",
        "                    self.__word_freq[word] = 1\n",
        "                    self.read_words(word)\n",
        "                else:\n",
        "                    self.__word_freq[word] += 1\n",
        "\n",
        "\n",
        "    \n",
        "    def read_words(self,word):\n",
        "            self.__word2int[word] = self.__num_unique_tokens\n",
        "            self.__int2word[self.__num_unique_tokens] = word\n",
        "            self.__num_unique_tokens+=1\n",
        "\n",
        "    def get_word_frequency(self):\n",
        "        return dict(sorted(self.__word_freq.items(),\n",
        "                           key=lambda x:x[1],\n",
        "                           reverse=True))\n",
        "    \n",
        "    def get_word2index(self):\n",
        "        return self.__int2word\n",
        "    \n",
        "    def get_index2word(self):\n",
        "        return self.__word2int\n",
        "    \n",
        "    def __integer_encoding(self,X):  \n",
        "        for word in X:\n",
        "            torch_tensor = torch.tensor(list(map(lambda word : self.__word2int[word],word)))\n",
        "            self.__integer_encoded.append(torch_tensor)\n",
        "\n",
        "    def get_integer_encoding(self,padding=True,max_len=None):\n",
        "        if padding:\n",
        "            return self.__pad_sequence(self.__integer_encoded,max_len)\n",
        "        else:\n",
        "            return self.__integer_encoded\n",
        "        \n",
        "    def __pad_sequence(self,X,max_len):\n",
        "            maxlen_padded = pad_sequence(self.__integer_encoded,padding_value=0,batch_first=True)\n",
        "            if max_len:\n",
        "                return maxlen_padded[:,:max_len]\n",
        "            else:\n",
        "                return maxlen_padded\n",
        "       \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "eng_lang = LangPorcess()\n",
        "eng_lang.fit(eng_data)\n",
        "\n",
        "mal_lang = LangPorcess()\n",
        "mal_lang.fit(mal_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "eng_integers = eng_lang.get_integer_encoding(max_len=11)\n",
        "mal_integers = mal_lang.get_integer_encoding(max_len=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TorchDataset(Dataset):\n",
        "    def __init__(self,enc_sentance,dec_sentance):\n",
        "        super().__init__()\n",
        "        self.enc_sentance = enc_sentance\n",
        "        self.dec_sentance = dec_sentance\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.enc_sentance)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.enc_sentance[index], self.dec_sentance[index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = TorchDataset(enc_sentance=eng_integers,dec_sentance=mal_integers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(data,\n",
        "                        batch_size=32,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 28,  51,  78, 251, 252,   0,   0,   0,   0,   0,   0],\n",
            "        [  6, 108, 109,  82,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  6,  33,  34,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  6, 189,  43,  18,  50, 366,   0,   0,   0,   0,   0],\n",
            "        [ 43,  76,  80,   4, 160,   0,   0,   0,   0,   0,   0],\n",
            "        [  6,  61,  18, 293,  16,   0,   0,   0,   0,   0,   0],\n",
            "        [494, 274, 495, 496,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [477, 186, 478, 237, 479,   0,   0,   0,   0,   0,   0],\n",
            "        [  6,   8,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [326, 399,   4, 400,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [683, 167,  80, 274, 181, 505, 405,   0,   0,   0,   0],\n",
            "        [ 98, 205, 456, 929, 930, 148, 153, 931,   0,   0,   0],\n",
            "        [ 16, 375, 150, 183, 398, 173,  80, 957,  80,  69, 792],\n",
            "        [  6, 185, 220,  87,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  6, 407, 569, 529, 536,   0,   0,   0,   0,   0,   0],\n",
            "        [ 28, 139, 474, 569, 590, 418,   0,   0,   0,   0,   0],\n",
            "        [  6, 179, 259,  80, 260,   0,   0,   0,   0,   0,   0],\n",
            "        [ 19,  69, 846, 553, 148,  69, 847,   0,   0,   0,   0],\n",
            "        [ 23, 120,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [  6,  29, 218,  18, 257,   0,   0,   0,   0,   0,   0],\n",
            "        [401,  19, 247,  64, 402,   0,   0,   0,   0,   0,   0],\n",
            "        [ 69, 642, 877, 115,  28,  43,  32, 270,   0,   0,   0],\n",
            "        [ 40, 208,  41,  42,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [180, 329, 330, 331,   0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 50,  51,  69, 910, 130,  69, 911, 912, 910,   0,   0],\n",
            "        [ 28,  51, 593, 322,  27, 594,   0,   0,   0,   0,   0],\n",
            "        [ 59, 365,  78, 366, 273,   0,   0,   0,   0,   0,   0],\n",
            "        [ 16, 114, 433,  80, 293, 255,  76,   0,   0,   0,   0],\n",
            "        [ 69, 406, 167, 836, 481, 601, 837, 142,   0,   0,   0],\n",
            "        [492,   6, 354,  28,  51, 493,   0,   0,   0,   0,   0],\n",
            "        [ 99,  18, 293,  93, 858, 751, 859, 672,   0,   0,   0],\n",
            "        [ 48, 182, 786, 848, 588,  78, 849, 392,   0,   0,   0]]) tensor([[  96,  149,  210,  268,    0,    0,    0],\n",
            "        [  10,  110,  111,  112,    0,    0,    0],\n",
            "        [  36,   37,    0,    0,    0,    0,    0],\n",
            "        [  10,   99,  251,  426,  529,    0,    0],\n",
            "        [ 164,  338,   48,    0,    0,    0,    0],\n",
            "        [ 229,   16,  323,  324,    6,   62,    0],\n",
            "        [ 609,  610,  611,  493,    0,    0,    0],\n",
            "        [  10,  251,  234,  585,  586,    0,    0],\n",
            "        [   8,    9,    0,    0,    0,    0,    0],\n",
            "        [ 363,  473,  474,    0,    0,    0,    0],\n",
            "        [ 915,  916,  917,    0,    0,    0,    0],\n",
            "        [ 158, 1328,  258, 1329,    0,    0,    0],\n",
            "        [1376,  180, 1377,   41,  470, 1378, 1379],\n",
            "        [   8,   85,  231,  232,    0,    0,    0],\n",
            "        [  10,  675,  732,  733,  483,    0,    0],\n",
            "        [  96,  732,  771,  772,  700,  773,    0],\n",
            "        [   6,  279,  280,    0,    0,    0,    0],\n",
            "        [ 251, 1204,  740,  360, 1205,    0,    0],\n",
            "        [  24,  123,   26,    0,    0,    0,    0],\n",
            "        [   8,  273,  274,  275,  276,   32,    0],\n",
            "        [ 475,  476,   65,  477,    0,    0,    0],\n",
            "        [ 292, 1257, 1258,  121, 1259,    0,    0],\n",
            "        [  44,   45,   46,    0,    0,    0,    0],\n",
            "        [ 126,  367,  368,    0,    0,    0,    0],\n",
            "        [ 251, 1295,   69, 1296,  974,    0,    0],\n",
            "        [  30,  777,  778,  779,    0,    0,    0],\n",
            "        [  96,  110,  149,  426,  427,    0,    0],\n",
            "        [  41,   20,  940,  365,    0,    0,    0],\n",
            "        [1190,  223, 1191,  481, 1192,    0,    0],\n",
            "        [ 606,  607,   96,  608,    0,    0,    0],\n",
            "        [1220, 1030, 1221, 1222, 1223,    0,    0],\n",
            "        [ 149,  460,  770, 1206,  120,   37,    0]])\n"
          ]
        }
      ],
      "source": [
        "for i,(inp,ter) in enumerate(dataloader):\n",
        "    if i ==1:\n",
        "        break\n",
        "    print(inp,ter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "lPp3w84uZiHC"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, \n",
        "               embedding_size, \n",
        "               hidden_size, \n",
        "               vocab_size):\n",
        "    super().__init__(self)\n",
        "\n",
        "    # encoder initialization\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                             embedding_dim=embedding_size)\n",
        "    self.encoder_lstm = nn.LSTM(input_size=embedding_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           batch_first=True)\n",
        "\n",
        "  def forward(self,input):\n",
        "    # network flow\n",
        "    embedding_input = self.embedding(input)\n",
        "    encoder_outputs, (final_hidden_state, final_cell_state) = self.encoder_lstm(embedding_input)\n",
        "    \n",
        "    return encoder_outputs, final_hidden_state, final_cell_state\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super().__init__(self)\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "          nn.Linear(2*hidden_size,hidden_size),\n",
        "          nn.SELU(),\n",
        "          nn.Linear(hidden_size,1),\n",
        "          nn.Softmax(dim=1)\n",
        "        )\n",
        "    \n",
        "  def forward(self,encoder_outputs,hidden_state):\n",
        "    \"\"\" Concat encoeder_output and hidden_state, encoder_output shape = (32,timestept,hidden_size), hidden_state shape = 32,1,hidden_side\n",
        "    first we need to make it same shape to concat hidden_state should be 32,timestep hidden_size, timestpe will be repeatation of same one vector from hidden size\"\"\"\n",
        "\n",
        "    encoder_timestep_len = encoder_outputs.size(1)  # hidden_size will be (1,32,hidden_size) according to doc we need to change\n",
        "    hidden_state = hidden_state.permute(1,0,2) # shape: (32,1,5)\n",
        "    hidden_repeated = hidden_state(1,encoder_timestep_len,1) # hidden_state repetation \n",
        "\n",
        "    # concat with encoder_output and hidden output\n",
        "    encoder_hidden_concat = torch.concat((encoder_outputs,hidden_repeated),dim=-1) # shape : 32,timestep,hidden_size*2\n",
        "    weights = self.network(encoder_hidden_concat) # (32,timestepe,1)\n",
        "    weights = weights.permute(0,2,1) # for bmm (32,1,timesteps)\n",
        "    context_vectores = weights.bmm(encoder_outputs) # 32,1,hidden_size\n",
        "    context_vectores = context_vectores.permute(1,0,2) # convert back to the way lstm take hidden state\n",
        "\n",
        "    return context_vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-0NVAH5Zq7w"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size_tr,\n",
        "               embedding_dim,\n",
        "               hidden_size,\n",
        "               max_len=20,\n",
        "               sos_token=1,\n",
        "               ):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.MAX_LEN = max_len\n",
        "    self.SOS_TOKEN = sos_token\n",
        "\n",
        "    # Layers Initialization\n",
        "    self.embedding_layer = nn.Embedding(vocab_size_tr, embedding_dim)\n",
        "    self.lstm_layer = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
        "    self.fnn = nn.Linear(hidden_size ,vocab_size_tr)\n",
        "    self.attention_vector = Attention(hidden_size)\n",
        "\n",
        "  def forward(self,\n",
        "              encoder_outputs,\n",
        "              hidden_state,\n",
        "              cell_state,\n",
        "              target_output=None):\n",
        "    \n",
        "    batch_size = encoder_outputs.shape[0]     # encoder gets the input from train loader which defines the batchsize\n",
        "    decoder_input = torch.empty(size=(batch_size,1),dtype=torch.long).fill_(self.SOS_TOKEN)     # Initialize first input [32 sos_tokens]\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for i in range(self.MAX_LEN):\n",
        "      output_logits ,hidden_state = self.forward_step(encoder_outputs,decoder_input, hidden_state, cell_state)\n",
        "      decoder_outputs.append(output_logits.unsqueeze(1))      # decoder ouput = [(32,vocab_size),...(32,vocab_size)], this list will have max_len item , lastly we will concat this to make (32,max_len,vocab_size)\n",
        "\n",
        "      # teacher_forcing, occurs if we give target_output in the decoder\n",
        "      if target_output:\n",
        "        decoder_input = target_output[:,i].unsqueeze(1)\n",
        "      else:\n",
        "        _, decoder_input = output_logits.topk(1,dim=-1)\n",
        "\n",
        "    decoder_final_output = torch.cat(decoder_outputs,dim=1)\n",
        "    return decoder_final_output\n",
        "\n",
        "  def forward_step(self,encoder_outputs, decoder_input, hidden_state, cell_state):\n",
        "    embedded_decoder_input = self.embedding_layer(decoder_input)      # embedded shape : (32,1,embedd_size), here 1 , becuase we are giving each word or token to decoder and make it predict next word\n",
        "    lstm_output, (decoder_hidden, decoder_cell) = self.lstm_layer(embedded_decoder_input, (hidden_state, cell_state))     # lstm_output: (32,1,hidden_size)\n",
        "    output_logit = self.fnn(lstm_output.squeeze(1))   # squeeze (32,1,hidden_size) -> 32,hidden_size\n",
        "    hidden_state = self.attention_vector(encoder_outputs, decoder_hidden)     # ouput_logits: (32,vocab_size) , 32 prediction of word , we will pic top item\n",
        "\n",
        "    return output_logit ,hidden_state , cell_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6_hxStX4-K9"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqAttentionModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               embedding_size,\n",
        "               hidden_size,\n",
        "               vocab_size_en,\n",
        "               vocab_size_tr):\n",
        "    super().__init__(self)\n",
        "\n",
        "    self.encoder = Encoder(embedding_size,\n",
        "                           hidden_size,\n",
        "                           vocab_size_en)\n",
        "\n",
        "    self.decoder = Decoder(embedding_size,\n",
        "                           hidden_size,\n",
        "                           vocab_size_tr,\n",
        "                           max_len=20,\n",
        "                           sos_token=1)\n",
        "\n",
        "    def forward(self, input, target_output):\n",
        "      encoder_outputs, encoder_hidden_state, encoder_cell_state = self.encoder(input)\n",
        "      decoder_output = self.decoder(encoder_outputs, encoder_hidden_state, encoder_cell_state, target_output)\n",
        "\n",
        "      return decoder_output\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GPU",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
